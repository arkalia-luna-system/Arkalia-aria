"""
ARKALIA ARIA - Syst√®me d'Alertes Automatiques
=============================================

Syst√®me d'alertes intelligent pour :
- Patterns d√©tect√©s (d√©clencheurs r√©currents)
- Pr√©dictions (crises anticip√©es)
- Corr√©lations importantes (sommeil-douleur, stress-douleur)
- Notifications bas√©es sur donn√©es sant√©
"""

from datetime import datetime
from enum import Enum
from typing import Any

from .database import DatabaseManager
from .logging import get_logger

logger = get_logger("alerts")


class AlertSeverity(Enum):
    """Niveaux de s√©v√©rit√© des alertes."""

    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"


class AlertType(Enum):
    """Types d'alertes."""

    PATTERN_DETECTED = "pattern_detected"
    PREDICTION_CRISIS = "prediction_crisis"
    CORRELATION_STRONG = "correlation_strong"
    HEALTH_SYNC = "health_sync"
    MEDICAL_APPOINTMENT = "medical_appointment"


class ARIA_AlertsSystem:
    """
    Syst√®me d'alertes automatiques ARIA.

    D√©tecte et g√©n√®re des alertes pour :
    - Patterns r√©currents dans les donn√©es de douleur
    - Pr√©dictions de crises
    - Corr√©lations importantes
    - √âv√©nements sant√©
    """

    def __init__(self, db_path: str = "aria_pain.db") -> None:
        """Initialise le syst√®me d'alertes."""
        self.db = DatabaseManager(db_path)
        self._init_alerts_table()

    def _init_alerts_table(self) -> None:
        """Initialise la table des alertes."""
        try:
            self.db.execute_update("""
                CREATE TABLE IF NOT EXISTS alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    alert_type TEXT NOT NULL,
                    severity TEXT NOT NULL,
                    title TEXT NOT NULL,
                    message TEXT NOT NULL,
                    data TEXT,
                    is_read INTEGER DEFAULT 0,
                    created_at TEXT NOT NULL DEFAULT (DATETIME('now'))
                )
                """)
            # Index pour requ√™tes fr√©quentes
            try:
                self.db.execute_update(
                    "CREATE INDEX IF NOT EXISTS idx_alerts_type ON alerts(alert_type)"
                )
                self.db.execute_update(
                    "CREATE INDEX IF NOT EXISTS idx_alerts_created ON alerts(created_at)"
                )
                self.db.execute_update(
                    "CREATE INDEX IF NOT EXISTS idx_alerts_read ON alerts(is_read)"
                )
            except Exception as e:
                # Ignorer les erreurs de cr√©ation d'index (peut d√©j√† exister)
                logger.debug(f"Index idx_alerts_read peut d√©j√† exister: {e}")
            logger.info("‚úÖ Table alerts initialis√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation table alerts: {e}")

    def create_alert(
        self,
        alert_type: AlertType,
        severity: AlertSeverity,
        title: str,
        message: str,
        data: dict[str, Any] | None = None,
    ) -> int:
        """
        Cr√©e une nouvelle alerte.

        Args:
            alert_type: Type d'alerte
            severity: Niveau de s√©v√©rit√©
            title: Titre de l'alerte
            message: Message d√©taill√©
            data: Donn√©es suppl√©mentaires (optionnel)

        Returns:
            ID de l'alerte cr√©√©e
        """
        try:
            import json

            data_json = json.dumps(data) if data else None
            self.db.execute_update(
                """
                INSERT INTO alerts (alert_type, severity, title, message, data)
                VALUES (?, ?, ?, ?, ?)
                """,
                (
                    alert_type.value,
                    severity.value,
                    title,
                    message,
                    data_json,
                ),
            )
            logger.info(f"‚úÖ Alerte cr√©√©e: {title}")
            # R√©cup√©rer l'ID
            rows = self.db.execute_query("SELECT last_insert_rowid() as id")
            return rows[0]["id"] if rows else 0
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation alerte: {e}")
            return 0

    def check_patterns(self, days_back: int = 30) -> list[dict[str, Any]]:
        """
        V√©rifie les patterns r√©currents et cr√©e des alertes.

        Args:
            days_back: Nombre de jours √† analyser

        Returns:
            Liste des alertes cr√©√©es
        """
        alerts_created = []
        try:
            from pattern_analysis.correlation_analyzer import CorrelationAnalyzer

            analyzer = CorrelationAnalyzer()
            triggers = analyzer.detect_recurrent_triggers(days_back=days_back)

            # V√©rifier si des d√©clencheurs r√©currents existent
            if triggers.get("triggers"):
                for trigger in triggers["triggers"][:5]:  # Top 5
                    if trigger.get("occurrences", 0) >= 3:
                        alert_id = self.create_alert(
                            alert_type=AlertType.PATTERN_DETECTED,
                            severity=AlertSeverity.WARNING,
                            title="D√©clencheur r√©current d√©tect√©",
                            message=f"Le d√©clencheur '{trigger.get('trigger', 'inconnu')}' "
                            f"appara√Æt {trigger.get('occurrences', 0)} fois "
                            f"dans les {days_back} derniers jours.",
                            data={"trigger": trigger, "days_back": days_back},
                        )
                        alerts_created.append({"id": alert_id, "trigger": trigger})
        except Exception as e:
            logger.warning(f"Erreur v√©rification patterns: {e}")

        return alerts_created

    def check_predictions(self) -> list[dict[str, Any]]:
        """
        V√©rifie les pr√©dictions de crises et cr√©e des alertes.

        Returns:
            Liste des alertes cr√©√©es
        """
        alerts_created = []
        try:
            from prediction_engine.ml_analyzer import ARIAMLAnalyzer

            ml_analyzer = ARIAMLAnalyzer()
            context = {
                "stress_level": 0.5,
                "fatigue_level": 0.5,
                "activity_intensity": 0.5,
            }
            prediction = ml_analyzer.predict_pain_episode(context)

            # V√©rifier si risque √©lev√©
            risk_level = prediction.get("risk_level", "low")
            probability = prediction.get("probability", 0.0)

            if risk_level in ["high", "critical"] or probability > 0.7:
                severity = (
                    AlertSeverity.CRITICAL
                    if risk_level == "critical" or probability > 0.9
                    else AlertSeverity.WARNING
                )
                alert_id = self.create_alert(
                    alert_type=AlertType.PREDICTION_CRISIS,
                    severity=severity,
                    title="Risque de crise d√©tect√©",
                    message=f"Probabilit√© de crise: {probability:.0%} "
                    f"(Niveau de risque: {risk_level})",
                    data={"prediction": prediction},
                )
                alerts_created.append({"id": alert_id, "prediction": prediction})
        except Exception as e:
            logger.warning(f"Erreur v√©rification pr√©dictions: {e}")

        return alerts_created

    def check_correlations(self, days_back: int = 30) -> list[dict[str, Any]]:
        """
        V√©rifie les corr√©lations importantes et cr√©e des alertes.

        Args:
            days_back: Nombre de jours √† analyser

        Returns:
            Liste des alertes cr√©√©es
        """
        alerts_created = []
        try:
            from pattern_analysis.correlation_analyzer import CorrelationAnalyzer

            analyzer = CorrelationAnalyzer()

            # Corr√©lation sommeil-douleur
            sleep_corr = analyzer.analyze_sleep_pain_correlation(days_back=days_back)
            sleep_strength = sleep_corr.get("correlation_strength", 0.0)

            if abs(sleep_strength) > 0.6:  # Corr√©lation forte
                alert_id = self.create_alert(
                    alert_type=AlertType.CORRELATION_STRONG,
                    severity=AlertSeverity.INFO,
                    title="Corr√©lation sommeil-douleur d√©tect√©e",
                    message=f"Corr√©lation forte ({sleep_strength:.0%}) entre "
                    f"la qualit√© du sommeil et la douleur.",
                    data={"correlation": sleep_corr, "type": "sleep_pain"},
                )
                alerts_created.append({"id": alert_id, "correlation": sleep_corr})

            # Corr√©lation stress-douleur
            stress_corr = analyzer.analyze_stress_pain_correlation(days_back=days_back)
            stress_strength = stress_corr.get("correlation_strength", 0.0)

            if abs(stress_strength) > 0.6:  # Corr√©lation forte
                alert_id = self.create_alert(
                    alert_type=AlertType.CORRELATION_STRONG,
                    severity=AlertSeverity.INFO,
                    title="Corr√©lation stress-douleur d√©tect√©e",
                    message=f"Corr√©lation forte ({stress_strength:.0%}) entre "
                    f"le niveau de stress et la douleur.",
                    data={"correlation": stress_corr, "type": "stress_pain"},
                )
                alerts_created.append({"id": alert_id, "correlation": stress_corr})
        except Exception as e:
            logger.warning(f"Erreur v√©rification corr√©lations: {e}")

        return alerts_created

    def get_alerts(
        self,
        limit: int = 50,
        offset: int = 0,
        unread_only: bool = False,
        alert_type: AlertType | None = None,
    ) -> dict[str, Any]:
        """
        R√©cup√®re les alertes.

        Args:
            limit: Nombre d'alertes √† retourner
            offset: Offset pour pagination
            unread_only: Retourner uniquement les non lues
            alert_type: Filtrer par type (optionnel)

        Returns:
            Dict avec les alertes et m√©tadonn√©es
        """
        try:
            query = "SELECT * FROM alerts WHERE 1=1"
            params: list[Any] = []

            if unread_only:
                query += " AND is_read = 0"
            if alert_type:
                query += " AND alert_type = ?"
                params.append(alert_type.value)

            query += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
            params.extend([limit, offset])

            rows = self.db.execute_query(query, tuple(params))

            # Compter le total
            count_query = "SELECT COUNT(*) as count FROM alerts WHERE 1=1"
            count_params: list[Any] = []
            if unread_only:
                count_query += " AND is_read = 0"
            if alert_type:
                count_query += " AND alert_type = ?"
                count_params.append(alert_type.value)

            total_rows = self.db.execute_query(count_query, tuple(count_params))
            total = total_rows[0]["count"] if total_rows else 0

            alerts = []
            for row in rows:
                import json

                alert_dict = dict(row)
                if alert_dict.get("data"):
                    try:
                        alert_dict["data"] = json.loads(alert_dict["data"])
                    except Exception as e:
                        # Ignorer les erreurs de parsing JSON pour alert data
                        logger.debug(f"Erreur parsing JSON alert data: {e}")
                alerts.append(alert_dict)

            return {
                "alerts": alerts,
                "total": total,
                "limit": limit,
                "offset": offset,
                "has_more": (offset + limit) < total,
            }
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration alertes: {e}")
            return {
                "alerts": [],
                "total": 0,
                "limit": limit,
                "offset": offset,
                "has_more": False,
            }

    def mark_as_read(self, alert_id: int) -> bool:
        """
        Marque une alerte comme lue.

        Args:
            alert_id: ID de l'alerte

        Returns:
            True si succ√®s
        """
        try:
            self.db.execute_update(
                "UPDATE alerts SET is_read = 1 WHERE id = ?", (alert_id,)
            )
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur marquage alerte: {e}")
            return False

    def mark_all_as_read(self) -> int:
        """
        Marque toutes les alertes comme lues.

        Returns:
            Nombre d'alertes marqu√©es
        """
        try:
            result = self.db.execute_update(
                "UPDATE alerts SET is_read = 1 WHERE is_read = 0"
            )
            return result
        except Exception as e:
            logger.error(f"‚ùå Erreur marquage toutes alertes: {e}")
            return 0

    def check_all(self, days_back: int = 30) -> dict[str, Any]:
        """
        V√©rifie tout et cr√©e les alertes n√©cessaires.

        Args:
            days_back: Nombre de jours √† analyser

        Returns:
            R√©sum√© des alertes cr√©√©es
        """
        logger.info("üîç V√©rification de toutes les alertes...")
        patterns = self.check_patterns(days_back=days_back)
        predictions = self.check_predictions()
        correlations = self.check_correlations(days_back=days_back)

        total = len(patterns) + len(predictions) + len(correlations)

        return {
            "patterns": len(patterns),
            "predictions": len(predictions),
            "correlations": len(correlations),
            "total": total,
            "timestamp": datetime.now().isoformat(),
        }


# Instance globale
_alerts_system: ARIA_AlertsSystem | None = None


def get_alerts_system() -> ARIA_AlertsSystem:
    """R√©cup√®re ou cr√©e l'instance du syst√®me d'alertes."""
    global _alerts_system
    if _alerts_system is None:
        _alerts_system = ARIA_AlertsSystem()
    return _alerts_system
