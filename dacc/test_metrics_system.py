#!/usr/bin/env python3
"""
Script de test pour le systÃ¨me de mÃ©triques ARIA
================================================

Teste tous les composants du systÃ¨me de mÃ©triques intÃ©grÃ©.
"""

import sys
from pathlib import Path

# Ajouter le rÃ©pertoire courant au Python path
sys.path.insert(0, str(Path(__file__).parent))

from metrics_collector.collectors.aria_metrics_collector import ARIA_MetricsCollector
from metrics_collector.dashboard.aria_metrics_dashboard import ARIA_MetricsDashboard
from metrics_collector.exporters.aria_metrics_exporter import ARIA_MetricsExporter
from metrics_collector.validators.aria_metrics_validator import ARIA_MetricsValidator


def test_metrics_collection():
    """Test la collecte des mÃ©triques."""
    print("ğŸš€ Test de collecte des mÃ©triques...")

    collector = ARIA_MetricsCollector(".")
    metrics = collector.collect_all_metrics()

    print(f"âœ… MÃ©triques collectÃ©es : {len(metrics)} sections")
    print(f"ğŸ“Š Fichiers Python : {metrics.get('python_files', {}).get('count', 0)}")
    print(
        f"ğŸ“ Lignes de code : {metrics.get('python_files', {}).get('total_lines', 0)}"
    )
    print(f"ğŸ§ª Tests : {metrics.get('tests', {}).get('test_files_count', 0)}")

    return metrics


def test_metrics_validation(metrics):
    """Test la validation des mÃ©triques."""
    print("\nğŸ” Test de validation des mÃ©triques...")

    validator = ARIA_MetricsValidator()
    validation_results = validator.validate_metrics(metrics)

    print("âœ… Validation terminÃ©e")
    print(f"ğŸ“Š Score : {validation_results.get('score', 0)}/100")
    print(
        f"âœ… Statut : {'Valide' if validation_results.get('is_valid', False) else 'Invalide'}"
    )
    print(f"ğŸš¨ Alertes : {len(validation_results.get('alerts', []))}")
    print(f"ğŸ’¡ Recommandations : {len(validation_results.get('recommendations', []))}")

    return validation_results


def test_metrics_export(metrics):
    """Test l'export des mÃ©triques."""
    print("\nğŸ“¤ Test d'export des mÃ©triques...")

    exporter = ARIA_MetricsExporter("test_metrics_reports")

    # Export JSON
    json_file = exporter.export_json(metrics)
    print(f"âœ… Export JSON : {json_file}")

    # Export Markdown
    md_file = exporter.export_markdown(metrics)
    print(f"âœ… Export Markdown : {md_file}")

    # Export HTML
    html_file = exporter.export_html(metrics)
    print(f"âœ… Export HTML : {html_file}")

    # Export CSV
    csv_file = exporter.export_csv(metrics)
    print(f"âœ… Export CSV : {csv_file}")

    return [json_file, md_file, html_file, csv_file]


def test_dashboard_generation(metrics):
    """Test la gÃ©nÃ©ration du dashboard."""
    print("\nğŸ¨ Test de gÃ©nÃ©ration du dashboard...")

    dashboard = ARIA_MetricsDashboard()
    html = dashboard.generate_dashboard_html(metrics)

    print(f"âœ… Dashboard gÃ©nÃ©rÃ© : {len(html)} caractÃ¨res")
    print(f"ğŸŒ Contient 'ARKALIA ARIA' : {'ARKALIA ARIA' in html}")
    print(f"ğŸ“Š Contient des mÃ©triques : {'10' in html or '0' in html}")

    # Sauvegarder le dashboard
    dashboard_file = Path("test_dashboard.html")
    dashboard_file.write_text(html, encoding="utf-8")
    print(f"ğŸ’¾ Dashboard sauvegardÃ© : {dashboard_file}")

    return dashboard_file


def test_health_status(metrics):
    """Test le statut de santÃ©."""
    print("\nğŸ¥ Test du statut de santÃ©...")

    validator = ARIA_MetricsValidator()
    health_status = validator.get_health_status(metrics)

    print(f"âœ… Statut de santÃ© : {health_status.get('status', 'unknown').upper()}")
    print(f"ğŸ“Š Score : {health_status.get('score', 0)}/100")
    print(f"ğŸ¨ Couleur : {health_status.get('color', 'unknown')}")
    print(f"ğŸš¨ Alertes : {health_status.get('alerts_count', 0)}")
    print(f"ğŸ’¡ Recommandations : {health_status.get('recommendations_count', 0)}")

    return health_status


def main():
    """Fonction principale de test."""
    print("ğŸš€ ARKALIA ARIA - Test du SystÃ¨me de MÃ©triques")
    print("=" * 60)

    try:
        # Test 1 : Collecte des mÃ©triques
        metrics = test_metrics_collection()

        # Test 2 : Validation des mÃ©triques
        validation_results = test_metrics_validation(metrics)

        # Test 3 : Export des mÃ©triques
        export_files = test_metrics_export(metrics)

        # Test 4 : GÃ©nÃ©ration du dashboard
        dashboard_file = test_dashboard_generation(metrics)

        # Test 5 : Statut de santÃ©
        health_status = test_health_status(metrics)

        # RÃ©sumÃ© final
        print("\n" + "=" * 60)
        print("ğŸ‰ RÃ‰SUMÃ‰ DES TESTS")
        print("=" * 60)
        print("âœ… Collecte des mÃ©triques : SUCCÃˆS")
        print("âœ… Validation des mÃ©triques : SUCCÃˆS")
        print(f"âœ… Export des mÃ©triques : SUCCÃˆS ({len(export_files)} fichiers)")
        print("âœ… GÃ©nÃ©ration du dashboard : SUCCÃˆS")
        print("âœ… Statut de santÃ© : SUCCÃˆS")

        print(f"\nğŸ“Š Score global : {validation_results.get('score', 0)}/100")
        print(f"ğŸ¥ Statut de santÃ© : {health_status.get('status', 'unknown').upper()}")

        print("\nğŸ“ Fichiers gÃ©nÃ©rÃ©s :")
        for file_path in export_files:
            print(f"  - {file_path}")
        print(f"  - {dashboard_file}")

        print(f"\nğŸŒ Pour voir le dashboard, ouvrez : {dashboard_file}")

        return 0

    except Exception as e:
        print(f"\nâŒ ERREUR : {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
