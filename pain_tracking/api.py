"""
Pain Tracking API - Module de suivi de la douleur ARIA
"""

from __future__ import annotations

from datetime import datetime
from typing import Any, TypedDict

from fastapi import HTTPException, Query
from pydantic import BaseModel, Field

from core import BaseAPI

# Cr√©er l'API de base
api = BaseAPI(
    prefix="",  # Pas de pr√©fixe ici, il sera ajout√© dans main.py
    tags=["Pain Tracking"],
    description="API de suivi de la douleur ARIA",
)

router = api.get_router()
logger = api.logger
db = api.db


def _init_tables() -> None:
    """Initialise les tables de la base de donn√©es."""
    try:
        # Cr√©er la table pain_entries
        db.execute_update("""
            CREATE TABLE IF NOT EXISTS pain_entries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                intensity INTEGER NOT NULL CHECK (intensity >= 0 AND intensity <= 10),
                physical_trigger TEXT,
                mental_trigger TEXT,
                activity TEXT,
                location TEXT,
                action_taken TEXT,
                effectiveness INTEGER CHECK (effectiveness >= 0 AND effectiveness <= 10),
                notes TEXT,
                who_present TEXT,
                interactions TEXT,
                emotions TEXT,
                thoughts TEXT,
                physical_symptoms TEXT,
                created_at TEXT NOT NULL DEFAULT (DATETIME('now'))
            )
            """)

        # Migration: ajouter les nouveaux champs seulement si la table existe d√©j√† SANS ces colonnes
        # V√©rifier si les colonnes existent avant de les ajouter
        try:
            # V√©rifier si la table existe
            table_exists = db.table_exists("pain_entries")
            if table_exists:
                existing_columns = [
                    row[1]
                    for row in db.execute_query("PRAGMA table_info(pain_entries)")
                ]
                new_columns = {
                    "who_present": "TEXT",
                    "interactions": "TEXT",
                    "emotions": "TEXT",
                    "thoughts": "TEXT",
                    "physical_symptoms": "TEXT",
                }
                for col_name, col_type in new_columns.items():
                    if col_name not in existing_columns:
                        try:
                            db.execute_update(
                                f"ALTER TABLE pain_entries ADD COLUMN {col_name} {col_type}"
                            )
                            logger.debug(f"‚úÖ Colonne {col_name} ajout√©e")
                        except Exception as e:
                            error_msg = str(e).lower()
                            # Ignorer seulement les erreurs de colonne d√©j√† existante
                            if (
                                "duplicate column" in error_msg
                                or "already exists" in error_msg
                            ):
                                logger.debug(f"Colonne {col_name} existe d√©j√†, ignor√©")
                            else:
                                logger.warning(
                                    f"Erreur lors de l'ajout de la colonne {col_name}: {e}"
                                )
        except Exception as e:
            # Si la table n'existe pas encore, c'est OK (sera cr√©√©e par CREATE TABLE IF NOT EXISTS)
            logger.debug(f"V√©rification colonnes: {e}")

        # Cr√©er les index pour optimiser les requ√™tes
        try:
            db.execute_update(
                "CREATE INDEX IF NOT EXISTS idx_pain_entries_timestamp ON pain_entries(timestamp)"
            )
        except Exception as e:
            # Index peut d√©j√† exister, ignorer
            api.logger.debug(f"Index idx_pain_entries_timestamp peut d√©j√† exister: {e}")
        try:
            db.execute_update(
                "CREATE INDEX IF NOT EXISTS idx_pain_entries_intensity ON pain_entries(intensity)"
            )
        except Exception as e:
            # Index peut d√©j√† exister, ignorer
            api.logger.debug(f"Index idx_pain_entries_intensity peut d√©j√† exister: {e}")
        try:
            db.execute_update(
                "CREATE INDEX IF NOT EXISTS idx_pain_entries_location ON pain_entries(location)"
            )
        except Exception as e:
            # Index peut d√©j√† exister, ignorer
            api.logger.debug(f"Index idx_pain_entries_location peut d√©j√† exister: {e}")
        try:
            db.execute_update(
                "CREATE INDEX IF NOT EXISTS idx_pain_entries_timestamp_intensity ON pain_entries(timestamp, intensity)"
            )
        except Exception as e:
            # Index peut d√©j√† exister, ignorer
            api.logger.debug(
                f"Index idx_pain_entries_timestamp_intensity peut d√©j√† exister: {e}"
            )
        logger.info("‚úÖ Tables pain_entries initialis√©es avec index")
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation tables: {e}")
        raise


def _fetch_all_entries() -> list[dict]:
    """R√©cup√®re toutes les entr√©es tri√©es par date (r√©centes d'abord)."""
    _init_tables()
    try:
        # Limiter √† 10000 entr√©es max pour √©viter surcharge m√©moire
        rows = db.execute_query(
            "SELECT * FROM pain_entries ORDER BY timestamp DESC, id DESC LIMIT 10000"
        )
        return [dict(row) for row in rows]
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration entr√©es: {e}")
        raise


class ActionEff(TypedDict):
    action: str
    avg_effectiveness: float
    samples: int


def _compute_basic_stats(rows: list[dict]) -> dict[str, Any]:
    """Calcule des statistiques simples utiles pour rapport et suggestions."""
    if not rows:
        return {
            "entries_count": 0,
            "avg_intensity": 0.0,
            "top_triggers": [],
            "best_actions": [],
            "time_peaks": [],
        }

    import statistics
    from collections import Counter, defaultdict

    intensities: list[int] = []
    trigger_counter: Counter[str] = Counter()
    action_effectiveness: dict[str, list[int]] = defaultdict(list)
    hour_counter: Counter[str] = Counter()

    for r in rows:
        intensities.append(int(r["intensity"]))
        if r["physical_trigger"]:
            trigger_counter[r["physical_trigger"]] += 1
        if r["action_taken"] and r["effectiveness"] is not None:
            action_effectiveness[r["action_taken"]].append(int(r["effectiveness"]))
        # pics horaires
        ts = r["timestamp"]
        try:
            tpart = ts.split("T")[1] if "T" in ts else "00:00:00"
            hour = tpart.split(":")[0]
        except Exception:
            hour = "00"
        hour_counter[hour] += 1

    avg_intensity = round(statistics.mean(intensities), 2) if intensities else 0.0

    top_triggers = [
        {"trigger": trig, "count": cnt} for trig, cnt in trigger_counter.most_common(5)
    ]

    best_actions: list[ActionEff] = []
    for action, effs in action_effectiveness.items():
        if effs:
            best_actions.append(
                ActionEff(
                    action=action,
                    avg_effectiveness=round(statistics.mean(effs), 2),
                    samples=len(effs),
                )
            )
    best_actions.sort(key=lambda x: x["avg_effectiveness"], reverse=True)
    best_actions = best_actions[:5]

    time_peaks = [{"hour": h, "count": c} for h, c in hour_counter.most_common(5)]

    return {
        "entries_count": len(rows),
        "avg_intensity": avg_intensity,
        "top_triggers": top_triggers,
        "best_actions": best_actions,
        "time_peaks": time_peaks,
    }


# ==== Sch√©mas ====

# Types de validation (d√©finitions supprim√©es - utilisation directe de Field)


class PainEntryIn(BaseModel):
    intensity: int = Field(..., ge=0, le=10)
    physical_trigger: str | None = Field(default=None, min_length=1, max_length=128)
    mental_trigger: str | None = Field(default=None, min_length=1, max_length=128)
    activity: str | None = Field(default=None, min_length=1, max_length=128)
    location: str | None = Field(default=None, min_length=1, max_length=128)
    action_taken: str | None = Field(default=None, min_length=1, max_length=128)
    effectiveness: int | None = Field(default=None, ge=0, le=10)
    notes: str | None = Field(default=None, max_length=2000)
    who_present: str | None = Field(
        default=None,
        max_length=500,
        description="Personnes pr√©sentes lors de l'√©pisode",
    )
    interactions: str | None = Field(
        default=None,
        max_length=1000,
        description="Qui dit/fait quoi - interactions observ√©es",
    )
    emotions: str | None = Field(
        default=None,
        max_length=1000,
        description="Ce que je ressens - √©motions et sensations",
    )
    thoughts: str | None = Field(
        default=None,
        max_length=2000,
        description="Ce que je pense - pens√©es et r√©flexions",
    )
    physical_symptoms: str | None = Field(
        default=None, max_length=1000, description="Sympt√¥mes physiques d√©taill√©s"
    )
    timestamp: str | None = None  # ISO format


class PainEntryOut(PainEntryIn):
    id: int
    timestamp: str
    created_at: str


class QuickEntry(BaseModel):
    """Saisie ultra-rapide - 3 questions seulement"""

    intensity: int = Field(..., ge=0, le=10)
    physical_trigger: str = Field(
        ..., min_length=1, max_length=128
    )  # D√©clencheur en un mot
    action_taken: str = Field(..., min_length=1, max_length=128)  # Action imm√©diate


# ==== Endpoints ====


@router.get("/status")
async def pain_tracking_status() -> dict:
    """Statut du module pain tracking"""
    return {
        "module": "pain_tracking",
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "features": [
            "quick_entry",
            "detailed_entry",
            "history",
            "export_csv",
            "export_psy_html",
            "suggestions",
        ],
    }


@router.post("/quick-entry", response_model=PainEntryOut)
async def create_quick_entry(entry: QuickEntry) -> PainEntryOut:
    """Saisie ultra-rapide - 3 questions seulement"""
    # Invalider le cache apr√®s cr√©ation d'entr√©e
    api.cache.invalidate_pattern("pain_entries_")
    api.cache.invalidate_pattern("pain_suggestions_")
    _init_tables()
    ts = datetime.now().isoformat()

    try:
        # Ins√©rer l'entr√©e
        db.execute_update(
            """
            INSERT INTO pain_entries (
                timestamp, intensity, physical_trigger, action_taken
            ) VALUES (?, ?, ?, ?)
            """,
            (ts, int(entry.intensity), entry.physical_trigger, entry.action_taken),
        )

        # R√©cup√©rer l'entr√©e cr√©√©e
        rows = db.execute_query("SELECT * FROM pain_entries ORDER BY id DESC LIMIT 1")
        if not rows:
            raise HTTPException(
                status_code=500, detail="Erreur lors de la cr√©ation de l'entr√©e"
            )

        logger.info(f"‚úÖ Entr√©e rapide cr√©√©e: intensit√© {entry.intensity}")
        return PainEntryOut(**dict(rows[0]))
    except HTTPException:
        raise
    except ValueError as e:
        logger.error(f"‚ùå Erreur validation donn√©es: {e}")
        raise HTTPException(
            status_code=400, detail=f"Donn√©es invalides: {str(e)}"
        ) from e
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation entr√©e rapide: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}") from e


@router.post("/entry", response_model=PainEntryOut)
async def create_pain_entry(entry: PainEntryIn) -> PainEntryOut:
    """Cr√©ation d'une entr√©e d√©taill√©e"""
    # Invalider le cache apr√®s cr√©ation d'entr√©e
    api.cache.invalidate_pattern("pain_entries_")
    api.cache.invalidate_pattern("pain_suggestions_")
    _init_tables()
    ts = entry.timestamp or datetime.now().isoformat()

    try:
        # Ins√©rer l'entr√©e d√©taill√©e
        db.execute_update(
            """
            INSERT INTO pain_entries (
                timestamp, intensity, physical_trigger, mental_trigger, activity,
                location, action_taken, effectiveness, notes,
                who_present, interactions, emotions, thoughts, physical_symptoms
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (
                ts,
                int(entry.intensity),
                entry.physical_trigger,
                entry.mental_trigger,
                entry.activity,
                entry.location,
                entry.action_taken,
                int(entry.effectiveness) if entry.effectiveness is not None else None,
                entry.notes,
                entry.who_present,
                entry.interactions,
                entry.emotions,
                entry.thoughts,
                entry.physical_symptoms,
            ),
        )

        # R√©cup√©rer l'entr√©e cr√©√©e
        rows = db.execute_query("SELECT * FROM pain_entries ORDER BY id DESC LIMIT 1")
        if not rows:
            raise HTTPException(
                status_code=500, detail="Erreur lors de la cr√©ation de l'entr√©e"
            )

        logger.info(f"‚úÖ Entr√©e d√©taill√©e cr√©√©e: intensit√© {entry.intensity}")
        return PainEntryOut(**dict(rows[0]))
    except HTTPException:
        raise
    except ValueError as e:
        logger.error(f"‚ùå Erreur validation donn√©es: {e}")
        raise HTTPException(
            status_code=400, detail=f"Donn√©es invalides: {str(e)}"
        ) from e
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation entr√©e d√©taill√©e: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}") from e


@router.get("/entries", response_model=dict)
async def list_pain_entries(
    limit: int = Query(50, ge=1, le=200, description="Nombre d'entr√©es √† retourner"),
    offset: int = Query(0, ge=0, description="Nombre d'entr√©es √† sauter"),
) -> dict[str, Any]:
    """
    Liste les entr√©es de douleur avec pagination.

    Args:
        limit: Nombre d'entr√©es √† retourner (d√©faut: 50, max: 200)
        offset: Nombre d'entr√©es √† sauter (d√©faut: 0)
    """
    _init_tables()
    try:
        # Limiter le nombre max pour √©viter surcharge
        limit = min(limit, 200)
        offset = max(offset, 0)

        # R√©cup√©rer les entr√©es avec pagination
        rows = db.execute_query(
            "SELECT * FROM pain_entries ORDER BY timestamp DESC, id DESC LIMIT ? OFFSET ?",
            (limit, offset),
        )

        # Compter le total
        total_rows = db.execute_query("SELECT COUNT(*) as count FROM pain_entries")
        total = total_rows[0]["count"] if total_rows else 0

        logger.info(f"üìã {len(rows)} entr√©es r√©cup√©r√©es (total: {total})")
        return {
            "entries": [PainEntryOut(**dict(row)) for row in rows],
            "total": total,
            "limit": limit,
            "offset": offset,
            "has_more": (offset + limit) < total,
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration entr√©es: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e


@router.get("/entries/recent", response_model=list[PainEntryOut])
async def list_recent(limit: int = 20) -> list[PainEntryOut]:
    """Liste les entr√©es r√©centes"""
    _init_tables()
    try:
        # V√©rifier le cache (cl√© bas√©e sur limit)
        cache_key = f"pain_entries_recent_{limit}"
        cached_result = api.cache.get(cache_key)
        if cached_result is not None:
            logger.debug(f"üì¶ Entr√©es r√©centes depuis cache (limit={limit})")
            return cached_result

        rows = db.execute_query(
            "SELECT * FROM pain_entries ORDER BY timestamp DESC, id DESC LIMIT ?",
            (limit,),
        )
        result = [PainEntryOut(**dict(row)) for row in rows]
        logger.info(f"üìã {len(rows)} entr√©es r√©centes r√©cup√©r√©es")

        # Mettre en cache (TTL 2 minutes car donn√©es r√©centes)
        api.cache.set(cache_key, result, ttl=120)
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration entr√©es r√©centes: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e


@router.get("/export/psy-report")
async def export_psy_report() -> dict[str, Any]:
    """Export HTML pr√™t √† imprimer pour psychologue.

    Retourne un objet JSON contenant le HTML et un nom de fichier recommand√©.
    """
    rows = _fetch_all_entries()
    stats = _compute_basic_stats(rows)

    # Construction HTML simple et lisible
    def html_escape(s: str) -> str:
        return (
            s.replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
            .replace('"', "&quot;")
            .replace("'", "&#39;")
        )

    rows_html = []
    for r in rows[:200]:  # limiter pour impression
        rows_html.append(
            f"<tr>"
            f"<td>{html_escape(str(r['timestamp']))}</td>"
            f"<td>{int(r['intensity'])}</td>"
            f"<td>{html_escape(str(r['physical_trigger'] or ''))}</td>"
            f"<td>{html_escape(str(r['mental_trigger'] or ''))}</td>"
            f"<td>{html_escape(str(r['activity'] or ''))}</td>"
            f"<td>{html_escape(str(r['location'] or ''))}</td>"
            f"<td>{html_escape(str(r['action_taken'] or ''))}</td>"
            f"<td>{html_escape(str(r['effectiveness'] or ''))}</td>"
            f"<td>{html_escape(str(r['notes'] or ''))}</td>"
            f"<td>{html_escape(str(r.get('who_present') or ''))}</td>"
            f"<td>{html_escape(str(r.get('interactions') or ''))}</td>"
            f"<td>{html_escape(str(r.get('emotions') or ''))}</td>"
            f"<td>{html_escape(str(r.get('thoughts') or ''))}</td>"
            f"<td>{html_escape(str(r.get('physical_symptoms') or ''))}</td>"
            f"</tr>"
        )

    def li_kv(title: str, value: str) -> str:
        return f"<li><strong>{html_escape(title)}:</strong> {html_escape(value)}</li>"

    top_triggers_html = "".join(
        f"<li>{html_escape(t['trigger'])} ‚Äî {t['count']} fois</li>"
        for t in stats["top_triggers"]
    )
    best_actions_html = "".join(
        f"<li>{html_escape(a['action'])} ‚Äî efficacit√© moyenne {a['avg_effectiveness']} (n={a['samples']})</li>"
        for a in stats["best_actions"]
    )
    time_peaks_html = "".join(
        f"<li>{html_escape(p['hour'])}h ‚Äî {p['count']} entr√©es</li>"
        for p in stats["time_peaks"]
    )

    html = f"""
<!doctype html>
<html lang=fr>
<head>
  <meta charset=utf-8>
  <title>Rapport Psychologue - ARIA</title>
  <style>
    body {{ font-family: -apple-system, Segoe UI, Roboto, sans-serif; margin: 24px; }}
    h1, h2 {{ margin: 0 0 8px 0; }}
    .muted {{ color: #666 }}
    .grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 16px; }}
    table {{ width: 100%; border-collapse: collapse; margin-top: 12px; }}
    th, td {{ border: 1px solid #ddd; padding: 6px 8px; font-size: 13px; }}
    th {{ background: #fafafa; text-align: left; }}
    ul {{ padding-left: 18px; }}
  </style>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name=generator content="ARIA">
  <meta name=created content="{datetime.now().isoformat()}">
  <meta name=entries content="{stats['entries_count']}">
  <meta name=avg_intensity content="{stats['avg_intensity']}">
  <meta name=privacy content="local-first">
  <meta name=category content="pain-tracking">
  <meta name=audience content="psychologist">
  <meta name=language content="fr">
  <meta name=format content="html-printable">
  <meta name=security content="anonymized">
  <meta name=confidentiality content="high">
  <meta name=compliance content="RGPD-local-only">
  <meta name=version content="1.0">
  <meta name=tool content="arkalia-aria">
  <meta name=report-type content="psy">
  <meta name=summary content="Synth√®se douleur, d√©clencheurs, interventions et historique">
  <meta name=export content="psy-report">
  <meta name=owner content="user-local">
  <meta name=hash content="">
  <meta name=notes content="">
  <meta name=tags content="douleur,psychologie,suivi">
  <meta name=retention content="user-controlled">
  <meta name=classification content="private">
  <meta name=scope content="personal-health">
  <meta name=origin content="local-db">
  <meta name=created-by content="arkalia-aria">
  <meta name=generated-by content="arkalia-aria">
  <meta name=license content="MIT">
  <meta name=terms content="local-use">
  <meta name=exported-at content="{datetime.now().isoformat()}">
</head>
<body>
  <h1>Rapport Psychologue</h1>
  <div class=muted>G√©n√©r√© par ARIA ‚Äî {datetime.now().strftime('%Y-%m-%d %H:%M')}</div>

  <h2>1. Synth√®se</h2>
  <ul>
    {li_kv('Nombre d‚Äôentr√©es', str(stats['entries_count']))}
    {li_kv('Intensit√© moyenne', str(stats['avg_intensity']))}
  </ul>

  <div class=grid>
    <div>
      <h2>2. Top d√©clencheurs</h2>
      <ul>{top_triggers_html or '<li>Aucun</li>'}</ul>
    </div>
    <div>
      <h2>3. Actions les plus efficaces</h2>
      <ul>{best_actions_html or '<li>Aucune</li>'}</ul>
    </div>
  </div>

  <h2>4. Pics horaires</h2>
  <ul>{time_peaks_html or '<li>Aucun</li>'}</ul>

  <h2>5. Historique d√©taill√© (dern. 200)</h2>
  <table>
    <thead>
      <tr>
        <th>Date/Heure</th><th>Intensit√©</th><th>D√©clencheur</th><th>Mental</th>
        <th>Activit√©</th><th>Localisation</th><th>Action</th><th>Efficacit√©</th><th>Notes</th>
        <th>Qui pr√©sent</th><th>Interactions</th><th>√âmotions</th><th>Pens√©es</th><th>Sympt√¥mes physiques</th>
      </tr>
    </thead>
    <tbody>
      {''.join(rows_html)}
    </tbody>
  </table>
</body>
</html>
"""

    return {
        "html": html,
        "filename": f"psy_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
        "entries_count": stats["entries_count"],
    }


@router.get("/suggestions")
async def pain_suggestions(window: int = 30) -> dict[str, Any]:
    """G√©n√®re des suggestions intelligentes bas√©es sur des r√®gles simples.

    window: nombre de jours r√©cents √† analyser (non strict ici, heuristique simple).
    """
    # V√©rifier le cache (cl√© bas√©e sur window)
    cache_key = f"pain_suggestions_{window}"
    cached_result = api.cache.get(cache_key)
    if cached_result is not None:
        logger.debug(f"üì¶ Suggestions depuis cache (window={window})")
        return cached_result

    rows = _fetch_all_entries()
    stats = _compute_basic_stats(rows)

    suggestions: list[str] = []

    # R√®gles d√©terministes simples et utiles en clinique
    if stats["avg_intensity"] >= 6:
        suggestions.append(
            "Intensit√© moyenne √©lev√©e: envisager des techniques de relaxation quotidiennes."
        )

    if stats["top_triggers"]:
        t0 = stats["top_triggers"][0]
        if t0["count"] >= 3:
            suggestions.append(
                f"D√©clencheur fr√©quent identifi√©: {t0['trigger']} ‚Äî pr√©voir strat√©gies d‚Äô√©vitement/att√©nuation."
            )

    if stats["best_actions"]:
        a0 = stats["best_actions"][0]
        if a0["avg_effectiveness"] >= 6:
            suggestions.append(
                f"Action efficace √† privil√©gier: {a0['action']} (efficacit√© moyenne {a0['avg_effectiveness']})."
            )

    if stats["time_peaks"]:
        p0 = stats["time_peaks"][0]
        suggestions.append(
            f"Pic horaire r√©current: {p0['hour']}h ‚Äî adapter les routines avant ce cr√©neau."
        )

    questions_precision: list[str] = []
    if not stats["top_triggers"]:
        questions_precision.append(
            "Avez-vous remarqu√© un d√©clencheur physique r√©current ces derniers jours ?"
        )
    if not stats["best_actions"]:
        questions_precision.append(
            "Quelles actions avez-vous essay√©es et avec quel effet (0-10) ?"
        )

    result = {
        "window_days": window,
        "summary": stats,
        "suggestions": suggestions,
        "follow_up_questions": questions_precision,
        "generated_at": datetime.now().isoformat(),
    }

    # Mettre en cache (TTL 5 minutes car calcul co√ªteux)
    api.cache.set(cache_key, result, ttl=300)
    return result


@router.get("/export/csv")
async def export_csv():
    """Export CSV pour professionnels de sant√©"""
    _init_tables()
    try:
        # Limiter √† 10000 entr√©es max pour √©viter surcharge m√©moire lors de l'export
        rows = db.execute_query(
            "SELECT * FROM pain_entries ORDER BY timestamp DESC LIMIT 10000"
        )

        # G√©n√©ration CSV simple
        csv_content = "Date,Heure,Intensit√©,D√©clencheur Physique,D√©clencheur Mental,Activit√©,Localisation,Action,Efficacit√©,Notes,Qui pr√©sent,Interactions,√âmotions,Pens√©es,Sympt√¥mes physiques\n"

        for row in rows:
            row_dict = dict(row)
            timestamp = row_dict["timestamp"]
            date, time = timestamp.split("T") if "T" in timestamp else (timestamp, "")
            csv_content += f"{date},{time},{row_dict['intensity']},{row_dict.get('physical_trigger') or ''},{row_dict.get('mental_trigger') or ''},{row_dict.get('activity') or ''},{row_dict.get('location') or ''},{row_dict.get('action_taken') or ''},{row_dict.get('effectiveness') or ''},{row_dict.get('notes') or ''},{row_dict.get('who_present') or ''},{row_dict.get('interactions') or ''},{row_dict.get('emotions') or ''},{row_dict.get('thoughts') or ''},{row_dict.get('physical_symptoms') or ''}\n"

        logger.info(f"üìä Export CSV g√©n√©r√©: {len(rows)} entr√©es")
        return {
            "content": csv_content,
            "filename": f"pain_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            "entries_count": len(rows),
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur export CSV: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e


@router.get("/export/pdf")
async def export_pdf():
    """Export PDF pour professionnels de sant√©"""
    _init_tables()
    try:
        # Limiter √† 10000 entr√©es max pour √©viter surcharge m√©moire lors de l'export
        rows = db.execute_query(
            "SELECT * FROM pain_entries ORDER BY timestamp DESC LIMIT 10000"
        )

        # G√©n√©ration PDF simple (format texte)
        pdf_content = f"""RAPPORT DE DOULEUR - ARKALIA ARIA
Date d'export: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
Nombre d'entr√©es: {len(rows)}

"""

        # En-t√™tes
        pdf_content += "DATE\tHEURE\tINTENSIT√â\tD√âCLENCHEUR PHYSIQUE\tD√âCLENCHEUR MENTAL\tACTIVIT√â\tLOCALISATION\tACTION\tEFFICACIT√â\tNOTES\tQUI PR√âSENT\tINTERACTIONS\t√âMOTIONS\tPENS√âES\tSYMPT√îMES PHYSIQUES\n"
        pdf_content += "-" * 200 + "\n"

        # Donn√©es
        for row in rows:
            row_dict = dict(row)
            timestamp = row_dict["timestamp"]
            date, time = timestamp.split("T") if "T" in timestamp else (timestamp, "")
            pdf_content += f"{date}\t{time}\t{row_dict['intensity']}\t{row_dict.get('physical_trigger') or ''}\t{row_dict.get('mental_trigger') or ''}\t{row_dict.get('activity') or ''}\t{row_dict.get('location') or ''}\t{row_dict.get('action_taken') or ''}\t{row_dict.get('effectiveness') or ''}\t{row_dict.get('notes') or ''}\t{row_dict.get('who_present') or ''}\t{row_dict.get('interactions') or ''}\t{row_dict.get('emotions') or ''}\t{row_dict.get('thoughts') or ''}\t{row_dict.get('physical_symptoms') or ''}\n"

        logger.info(f"üìÑ Export PDF g√©n√©r√©: {len(rows)} entr√©es")
        return {
            "content": pdf_content,
            "filename": f"pain_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
            "entries_count": len(rows),
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur export PDF: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e


@router.get("/export/excel")
async def export_excel():
    """Export Excel pour professionnels de sant√©"""
    _init_tables()
    try:
        # Limiter √† 10000 entr√©es max pour √©viter surcharge m√©moire lors de l'export
        rows = db.execute_query(
            "SELECT * FROM pain_entries ORDER BY timestamp DESC LIMIT 10000"
        )

        # G√©n√©ration Excel (format CSV avec s√©parateur tab)
        excel_content = "Date\tHeure\tIntensit√©\tD√©clencheur Physique\tD√©clencheur Mental\tActivit√©\tLocalisation\tAction\tEfficacit√©\tNotes\tQui pr√©sent\tInteractions\t√âmotions\tPens√©es\tSympt√¥mes physiques\n"

        for row in rows:
            row_dict = dict(row)
            timestamp = row_dict["timestamp"]
            date, time = timestamp.split("T") if "T" in timestamp else (timestamp, "")
            excel_content += f"{date}\t{time}\t{row_dict['intensity']}\t{row_dict.get('physical_trigger') or ''}\t{row_dict.get('mental_trigger') or ''}\t{row_dict.get('activity') or ''}\t{row_dict.get('location') or ''}\t{row_dict.get('action_taken') or ''}\t{row_dict.get('effectiveness') or ''}\t{row_dict.get('notes') or ''}\t{row_dict.get('who_present') or ''}\t{row_dict.get('interactions') or ''}\t{row_dict.get('emotions') or ''}\t{row_dict.get('thoughts') or ''}\t{row_dict.get('physical_symptoms') or ''}\n"

        logger.info(f"üìä Export Excel g√©n√©r√©: {len(rows)} entr√©es")
        return {
            "content": excel_content,
            "filename": f"pain_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            "entries_count": len(rows),
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur export Excel: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e


@router.delete("/entries/{entry_id}")
async def delete_pain_entry(entry_id: int):
    """Supprime une entr√©e de douleur (RGPD - Droit √† l'oubli)"""
    _init_tables()
    try:
        # V√©rifier que l'entr√©e existe
        existing = db.execute_query(
            "SELECT id FROM pain_entries WHERE id = ?", (entry_id,)
        )
        if not existing:
            raise HTTPException(status_code=404, detail="Entr√©e non trouv√©e")

        # Supprimer l'entr√©e
        db.execute_query("DELETE FROM pain_entries WHERE id = ?", (entry_id,))

        logger.info(f"üóëÔ∏è Entr√©e {entry_id} supprim√©e (RGPD)")
        return {
            "message": f"Entr√©e {entry_id} supprim√©e avec succ√®s",
            "entry_id": entry_id,
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur suppression entr√©e {entry_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e


@router.delete("/entries")
async def delete_all_pain_entries():
    """Supprime toutes les entr√©es de douleur (RGPD - Droit √† l'oubli complet)"""
    _init_tables()
    try:
        # Compter les entr√©es avant suppression
        count_result = db.execute_query("SELECT COUNT(*) as count FROM pain_entries")
        count = count_result[0]["count"] if count_result else 0

        # Supprimer toutes les entr√©es
        db.execute_query("DELETE FROM pain_entries")

        logger.info(f"üóëÔ∏è Toutes les entr√©es supprim√©es (RGPD): {count} entr√©es")
        return {
            "message": "Toutes les entr√©es supprim√©es avec succ√®s",
            "deleted_count": count,
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur suppression compl√®te: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}") from e
